{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa877c14",
   "metadata": {},
   "source": [
    "# TF-co-occurences for WP2 - Data\n",
    "### Outline of this notebook:\n",
    "    1. Constants, Path and Interface Definitions \n",
    "    2. Market Basket analysis with tf-comb, for all cluster/celltypes of a tissue\n",
    "    3. Differential analysis with all market basket analysis (CombObj ´s) of step 2 for the clusters/celltypes of a single tissue. (One DiffCombObj for each tissue)\n",
    "    4. Analysis for biological questions \n",
    "    \n",
    "The aim is to find transcription-factor-co-occurences for cluster/celltypes of human tissues with the help of the python-library tf-comb. For the data of WP2. The data basis comes from the \"cell atlas of chromatin accessibility across 25 adult human tissues\"(https://doi.org/10.1101/2021.02.17.431699) \n",
    "\n",
    "**Biological question, that we want to answer with this notebook:**\n",
    "\n",
    "1. Find Transcriptionfactor-co-occurences, which only occure in one (or more) \"cluster/celltypes of a tissue\".\n",
    "    Maybe we can identify a cluster through this co-occurences.\n",
    "\n",
    "**How to use this notbook:**\n",
    "1. Please adapted the paths in Constants, Path and interface defintions for your approach\n",
    "2. Please make sure you have installed the kernel as it is described in the ReadMe\n",
    "3. Check if the WP2 Data structure is correctly provided (ReadMe).\n",
    "    - Has all tissues as a folder in it: ../OUPTPUT_FOLDER/\n",
    "    - You find the data (open cromatin regions per cluster .bed-files) e.g ../OUPTPUT_FOLDER/<tissue>/WP6/*cluster_x.bed\n",
    "4. Execute each notebook window from top to bottom one after another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1aab90",
   "metadata": {},
   "source": [
    "## 1. Constants, Path and Interface Definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487586df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfcomb import CombObj, DiffCombObj, utils\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "'''\n",
    "Constants for this script.\n",
    "\n",
    "This window contains all paths and constants, which are later used for this juypter notbook.\n",
    "\n",
    "Please adapt paths or constants, if use other files. \n",
    "For example adapted the genome path, if you use another genome. \n",
    "'''\n",
    "\n",
    "# Path to genome fasta file. Is used for the market basket analysis of tfcomb.\n",
    "genome_path=\"/mnt/workspace_stud/allstud/homo_sapiens.104.mainChr.fa\"\n",
    "\n",
    "# Path to the jaspar file (contains transcription factors (TF) binding profiles\n",
    "# as position frequency matrices (PFMs)). Is used for the market basket analysis of tfcomb\n",
    "main_jaspar_file=\"../testdaten/JASPAR2020_CORE_vertebrates.meme\" \n",
    "\n",
    "# Path where results of this notebook will be written to (eg. TF_COMB objects, .pkl).\n",
    "result_path=\"./results/wp2/\"\n",
    "\n",
    "# Paths in the result folder:\n",
    "# Path to folder, where the resulting market basket analysis for a cluster/celltype is put \n",
    "main_analysis_path=f\"{result_path}main/\"\n",
    "\n",
    "# Path to folder, where the differential analysis for a tissue is put \n",
    "differential_analysis_path=f\"{result_path}diff_analysis/\"\n",
    "# Path to folder, where answers of our results are put to\n",
    "answers_path=f\"{result_path}answers/\"\n",
    "\n",
    "# Path to folder (Interface folder) of wp2, where the clusters of each tissue can be found.\n",
    "path_to_tissues=\"/mnt/workspace_stud/stud3/WP2_OUTPUT/FINISHED/\"\n",
    "\n",
    "# Tag for WP6 data in WP2 Interface\n",
    "cluster_folder_tag=\"WP6/\"\n",
    "\n",
    "# Path to Folder with celltype annotation tables of wp2\n",
    "celltype_annotation_path = \"/mnt/workspace_stud/stud4/celltype_assignment_tables/\"\n",
    "\n",
    "# The following lines, initally check if all file/paths are available. \n",
    "# If a result folder does not exist it is created automatically\n",
    "if not os.path.exists(result_path):\n",
    "     pathlib.Path(result_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(main_analysis_path):\n",
    "     pathlib.Path(main_analysis_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(differential_analysis_path):\n",
    "     pathlib.Path(differential_analysis_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(answers_path):\n",
    "     pathlib.Path(answers_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(genome_path):\n",
    "    print(f\"ERROR: path {genome_path} does not exist\")\n",
    "\n",
    "if not os.path.exists(main_jaspar_file):\n",
    "    print(f\"ERROR: path {main_jaspar_file} does not exist\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11adea88",
   "metadata": {},
   "source": [
    "### Helper functions for reading-in folders/files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e608ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_names_in_folder(rel_folder_path:str):\n",
    "    ''' \n",
    "        Read in the names of the folders in a folder.(rel_folder_path)\n",
    "        ---\n",
    "        Parameters:\n",
    "        \n",
    "        rel_folder_path: String\n",
    "            relative Path to the folder location that is read in.\n",
    "        ---\n",
    "        Return: a List of Strings (folder names)\n",
    "    '''\n",
    "\n",
    "    dirlist = [ item for item in os.listdir(rel_folder_path) if os.path.isdir(os.path.join(rel_folder_path, item))]\n",
    "    folder_names = []\n",
    "    for folder in dirlist:\n",
    "        folder_names.append(folder)\n",
    "    return folder_names\n",
    "\n",
    "def read_in_file_names_of_folder(rel_path:str):\n",
    "    ''' \n",
    "        Read in the file names in a folder (rel_path).\n",
    "        ---\n",
    "        Parameters:\n",
    "        \n",
    "        rel_path: String\n",
    "            relative Path to the folder location.\n",
    "        ---\n",
    "        Return: a List of Strings (file names)\n",
    "    '''\n",
    "    return [f for f in os.listdir(rel_path) if os.path.isfile(os.path.join(rel_path, f))]\n",
    "\n",
    "\n",
    "#cluster_file_names = read_in_file_names_of_folder(rel_path=path_to_clusters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0dba2e",
   "metadata": {},
   "source": [
    "## 2. Market basket analysis with tf-comb\n",
    "We do a market basket analysis with tfcomb for each cluster/celltype, which has been culstered by WP2 and comes from the raw single-cell ATAC-Data of the cell atlas project. As a result, we get the transcription-factor-co-occurences for each cluster. The Trancriptionsfactor motif´s come as a position-frequency-matrix from https://jaspar.genereg.net/search?q=&collection=CORE&tax_group=vertebrates. The corresponding genome, which is used is **homo_sapiens.104.mainChr.fa** .\n",
    "\n",
    "Approach:\n",
    "1. Read-in tissue folders of WP2\n",
    "2. For each tissue: read-in single .bed (Content= open-chromatin regions) files for each cluster/celltype\n",
    "3. Do market basket analysis for each cluster/celltype\n",
    "4. Result .pkl CombObj files can be found under **/{result_path}/{main_analysis_path}/{tissue_name}/{cluster_name}.pkl **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f22f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_market_basket_analyses_for_cell_cluster(mb_file_name: str, cell_cluster_path:str, tissue:str):\n",
    "    '''\n",
    "        Does market basket analysis with tfcomb. Saves the tfcomb-Object as .pkl file to main_analysis_path.\n",
    "        ---\n",
    "        Paramater:\n",
    "        \n",
    "        mb_file_name: string\n",
    "            Name for the result file of the market basket analyses. \n",
    "            e.g \"<tissue>_<cluster_number>_<celltype>\".\n",
    "        \n",
    "        cell_cluster_path: string\n",
    "            Path to the .bed-File with genome regions to check for tf-co-occurences\n",
    "         \n",
    "        tissue: string\n",
    "            Tissue name, origin of the cluster.\n",
    "    '''    \n",
    "    # Save path initalization, if folder for tissue does not exists, new folder is created.\n",
    "    save_path = f'{main_analysis_path}{tissue}/'\n",
    "    if not os.path.exists(save_path):\n",
    "         pathlib.Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # TF-comb market basket analysis\n",
    "    comb = CombObj()\n",
    "    comb.TFBS_from_motifs(regions= cell_cluster_path,\n",
    "                   motifs=main_jaspar_file,\n",
    "                   genome=genome_path,\n",
    "                   threads=4)\n",
    "    \n",
    "    print(f'Start market basket analyses for cell-cluster/type: {mb_file_name}')\n",
    "    comb.market_basket(threads=10)\n",
    "    \n",
    "    # if rules are empty nothing is saved \n",
    "    if len(comb.rules) <= 0:\n",
    "        print(f'Could not find TF-cooccurences for cell-cluster/type: {mb_file_name}')\n",
    "        return\n",
    "    print(f'Finished market basket analyses for cell-cluster/type: {mb_file_name}')\n",
    "    print(f'Found rules: {len(comb.rules)}')\n",
    "    \n",
    "    # save tf-comb obj to .pkl\n",
    "    comb.to_pickle(f'{save_path}{mb_file_name}.pkl')\n",
    "    print(f'Saved: {save_path}{mb_file_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dceb84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load tissue folder names for wp2 data\n",
    "tissues=get_folder_names_in_folder(rel_folder_path=path_to_tissues)\n",
    "print(tissues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f4a27",
   "metadata": {},
   "source": [
    "### Functions for adding the celltype annotations of wp2 to the corresponding clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e9bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_celltype_annotation_table(celltype_annotation_path:str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Read in the the given annotation file(celltype_annotation_path) with pandas read_table function\n",
    "    ---\n",
    "    Parameters:\n",
    "    celltype_annotation_path : string\n",
    "        Is the path to a file which has the celltype annotations for the cluster numbers.\n",
    "        e.g. file content:\n",
    "        6\tStromal cells\n",
    "        3\tAdipocyte progenitor cells\n",
    "        4\tStromal cells\n",
    "        7\tFibroblasts\n",
    "    ---\n",
    "    Returns a celltype annotation table as a pandas Dataframe.\n",
    "    '''\n",
    "    df = pd.read_table(celltype_annotation_path, header=None, index_col=None)\n",
    "    return df\n",
    "\n",
    "def get_celltype_for_cluster(cluster_number: int, celltype_annotation_table: pd.DataFrame):\n",
    "    '''\n",
    "    Find celltype annotation for cluster number in the corresponding celltype_annotation_table\n",
    "    ---\n",
    "    Parameters:\n",
    "    cluster_number: integer\n",
    "        number of the cluster\n",
    "    \n",
    "    celltype_annotation_table: pd.DataFrame\n",
    "        table with the celltype annotations, e.g. Dataframe\n",
    "         0\t1 \n",
    "       1 6\tStromal cells\n",
    "       2 3\tAdipocyte progenitor cells\n",
    "       3 4\tStromal cells\n",
    "       4 7\tFibroblasts\n",
    "    ---\n",
    "    Returns the celltype for a cluster_number. (if no celltype kann be found \"na\" is returned) \n",
    "    '''\n",
    "    # initalize celltype name with na (not available), if no celltype can be found na is returned\n",
    "    celltype_name = \"na\"\n",
    "    try:\n",
    "        # Try to find the cell-type annotation in the table, if no annotation can be found key error is raised\n",
    "        celltype_name = celltype_annotation_table[celltype_annotation_table[0] == int(cluster_number)].at[0,1]\n",
    "        # replace whitespaces in celltype names, e.g. \"Stromal cell\" -> \"Stromal_cell\"\n",
    "        celltype_name = celltype_name.replace(\" \", \"_\")\n",
    "    except KeyError:\n",
    "        print(f\"Could not find celltype annotation for cluster: {cluster_number}\")\n",
    "   \n",
    "    return celltype_name\n",
    "\n",
    "##remove\n",
    "celltype_annotations=read_in_file_names_of_folder(rel_path=celltype_annotation_path)\n",
    "print(celltype_annotations[0].split('_table_')[1])\n",
    "df = pd.read_table(f\"{celltype_annotation_path}{celltype_annotations[0]}\", header=None, index_col=None)\n",
    "print(celltype_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac05c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove \n",
    "try:\n",
    "    name = df[df[0] == 6].at[0,1]\n",
    "    name1 = name.replace(\" \", \"_\")\n",
    "    print(name)\n",
    "    print(name1)\n",
    "except KeyError:\n",
    "    print(f\"Error\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e4bd1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_mb_for_clusters(path_to_clusters:str, tissue:str):\n",
    "    '''\n",
    "        Wrapper function, that does the market basket analysis for all clusters/celltypes in a tissue.\n",
    "        Also annotates the cluster with a celltype.\n",
    "        ---\n",
    "        Paramater:\n",
    "        \n",
    "        path_to_clusters: string\n",
    "            Path to the .bed files(cluster) of a tissue.\n",
    "         \n",
    "        tissue: string\n",
    "            Tissue name from where the cluster corresponds to.\n",
    "        --- \n",
    "        Catch Exceptions with a message, if any error occures in the market basket analyses a message is printed\n",
    "        and the programm continues with the next tissue.\n",
    "    '''\n",
    "    # Read in the .bed files for each cluster of the specific tissue\n",
    "    cluster_file_names = read_in_file_names_of_folder(rel_path=path_to_clusters)\n",
    "    print(cluster_file_names)\n",
    "    \n",
    "    # Get the celltype annotation table. To add celltype for a cluster. e.g. cluster6 = fibroblast\n",
    "    celltype_table = pd.DataFrame()\n",
    "    # TODO:\n",
    "    #celltype_table = get_celltype_annotation_table(\n",
    "     #   celltype_annotation_path=f'{path_to_tissues}annotaion/annotation.txt') # pandas dataframe is returned\n",
    "    \n",
    "    # Do a market basket analysis for each cluster of a tissue\n",
    "    for file_name in cluster_file_names:\n",
    "        # e.g JF1O6_body_of_pancreas.10_peaks.bed -> [JF1O6_body_of_pancreas.10_peaks] = clustername = JF1O6_body_of_pancreas.10_peaks\n",
    "        cluster_name = file_name.split('.bed')[0]\n",
    "        #e.g JF1O6_body_of_pancreas.10_peaks -> [JF1O6_body_of_pancreas, 10_peaks], cluster_number_with_tag = 10_peaks\n",
    "        cluster_number_with_tag = cluster_name.split('.')[1]\n",
    "        # e.g 10_peaks -> [10 , peaks], cluster_number = 10\n",
    "        cluster_number = int(cluster_number_with_tag.split('_')[0])\n",
    "        \n",
    "        celltype_name = get_celltype_for_cluster(cluster_number=cluster_number,\n",
    "                                                 celltype_annotation_table=celltype_table)\n",
    "        \n",
    "        try:\n",
    "            print(cluster_name)\n",
    "            print(cluster_number)\n",
    "            print(celltype_name)\n",
    "            print(file_name)\n",
    "            # Prepare names and paths\n",
    "            cluster_path=f\"{path_to_clusters}{file_name}\"\n",
    "            # e.g. JF1O6_body_of_pancreas_c3_fibroblast\n",
    "            mb_file_name = f\"{tissue}_c{str(cluster_number)}_{celltype_name}\"\n",
    "            \n",
    "            do_market_basket_analyses_for_cell_cluster(mb_file_name=mb_file_name, cell_cluster_path=cluster_path, tissue=tissue)\n",
    "        except Exception:\n",
    "            print(f\"ERROR: Market basket for cluster:{cluster_name} in tissue {tissue}, did not work\")\n",
    "            continue\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e7350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a market basket analysis for each cluster of the tissue\n",
    "for tissue in tissues:\n",
    "    path_to_clusters = f\"{path_to_tissues}{tissue}/{cluster_folder_tag}\"\n",
    "    make_mb_for_clusters(path_to_clusters=path_to_clusters, tissue=tissue)\n",
    "\n",
    "print(\"DONE: Created market basket analysis for each cluster\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9872a4",
   "metadata": {},
   "source": [
    "## 3. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c16c5d",
   "metadata": {},
   "source": [
    "### Differential Analysis\n",
    "We use the differential analysis of tfcomb to identifiy the differences of tf-co-occurences between all cluster/celltypes of a tissue. For this we load all market basket analysis (tfcomb-objects) of a tissue (see point 2) into a DiffCombObj. After the differential analysis, we filter the object, so that we hopefully find tf-co-occurences that only occure in a single cluster of that tissue or only in a special celltype.  \n",
    "\n",
    "- mb = market basket analysis (CombObj of tf comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b5cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the tissue names by folder names of the market basket analysis \n",
    "mb_tissues = get_folder_names_in_folder(rel_folder_path=main_analysis_path)\n",
    "print(mb_tissues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929be533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_differential_analysis_for_tissues(tissues=[]):\n",
    "    '''\n",
    "        Differential analysis between all clusters/celltypes of a tissue.\n",
    "        ---\n",
    "        Paramater:\n",
    "        \n",
    "        tissues: array\n",
    "            tissue names by market basket analysis.\n",
    "        ---\n",
    "        DiffCombObj are saved as .pkl to differential_analysis_path\n",
    "    '''\n",
    "    for tissue_folder in tissues:\n",
    "        \n",
    "        diff_save_path = f\"{differential_analysis_path}{tissue_folder}/\"\n",
    "        # Check if  folder for differential_analysis already exists for tissue, if not create new one\n",
    "        if not os.path.exists(diff_save_path):\n",
    "             pathlib.Path(diff_save_path).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # get file names of the market basket analysis\n",
    "        tissue_mb_files = read_in_file_names_of_folder(rel_path=f\"{main_analysis_path}{tissue_folder}/\")\n",
    "        \n",
    "        # holds the combobj´s\n",
    "        tissue_mbs_to_compare = []\n",
    "        for file in tissue_mb_files:\n",
    "            print(file)\n",
    "            file_name = file.split('.pkl')[0]\n",
    "            # Load the CombObj (market basket analysis) for each cluster of a tissue\n",
    "            obj = CombObj().from_pickle(f\"{main_analysis_path}{tissue_folder}/{file}\")\n",
    "            obj.set_prefix(file_name)\n",
    "            tissue_mbs_to_compare.append(obj)\n",
    "        \n",
    "        # Create DiffCombObj with all Combobj (market basket analysis) of the clusters in a tissue\n",
    "        compare_obj = DiffCombObj(tissue_mbs_to_compare, measure=\"cosine\", join=\"outer\", fillna=True)\n",
    "        # save diffcombj\n",
    "        compare_obj.to_pickle(f'{diff_save_path}{tissue_folder}.pkl')\n",
    "        # Normalize the DiffCombObj\n",
    "        compare_obj.normalize()\n",
    "        compare_obj.calculate_foldchanges()\n",
    "        \n",
    "        # Remove rules which are doubled, e.g. A-B, B-A; (B-A) is removed\n",
    "        compare_obj.simplify_rules()\n",
    "        # Save the normalized, foldchange calculated and simplified diff_comb_obj to .pkl\n",
    "        compare_obj.to_pickle(f'{diff_save_path}{tissue_folder}_normalized.pkl')\n",
    "        print(f\"Done: Diff analysis for tissue {tissue_folder}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f520dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the differential analysis for all clusters in a tissue \n",
    "do_differential_analysis_for_tissues(tissues=mb_tissues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d4d9b5",
   "metadata": {},
   "source": [
    "# 4. Specific analysis  :\n",
    "### Biological Question:\n",
    " Find Transcriptionfactor-co-occurences, which only occure in one (or more) \"cluster/celltype of a tissue\".\n",
    " - Solution with a hard threshold (a, all cluster) or a week threshold (b, celltypes in a tissue):\n",
    "       - a) The found TF-pair occures only in a single cluster of a tissue:\n",
    "            e.g. Cluster1 has TF1-TF1 and the other cluster in the tissue do not have TF1-TF1.\n",
    "       - b) A TF-pair occures significantly only in some clusters:\n",
    "            e.g. We have 3 endothelcells cluster in a tissue and this three clusters share a TF-pair\n",
    "            which does not occure in the other cluster of the tissue. (need celltype annotation)\n",
    "          \n",
    "###  Steps:\n",
    "1. Read in tfcomb-DiffObj´s of the Differential analysis (Point 3)\n",
    "2. Get the rules of the DiffCombObj\n",
    "3. Filter the DiffCombObj rules for each cluster in it:\n",
    "       - e.g. investigate cluster1: get all log2changes col,\n",
    "         where cluster1 is associated with and his cosine column\n",
    "       - than filter the rules (tf-pairs) for tf-pairs with a significant change in the log2changes\n",
    "       - We would like to find TF-pairs that show a significant change in the log2changes in each contrast,\n",
    "         because this indicates a TF-Pair, which is striking for the investigated cluster in that tissue.\n",
    "         And a high cosine would be a indication, that the found tf-pair is really \n",
    "         a tf-co-occurence in that cluster.\n",
    "       - To find a TF-pair, which only occures in a single cluster of a tissue,\n",
    "         we check the log2changes in each col of the significant tf-pairs, if they have the same value,\n",
    "         the tf-pair only occures in that cluster in the tissue. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505cb1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the folder names of the tissues that have a differential analysis\n",
    "diff_mb_tissues = get_folder_names_in_folder(rel_folder_path=differential_analysis_path)\n",
    "print(diff_mb_tissues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d56ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significant_rules(df:pd.DataFrame, cosine_col:str, cosine_threshold=0.001, log2fc_threshold_percent=0.05):\n",
    "    '''\n",
    "    Filter a rules Dataframe (tf-pairs) by log2foldchange col´s and cosine col´s of a DiffCombObj for significant tf-co-occurences (tf-pairs).\n",
    "    Only the TF-pairs with significant log2foldchanges per contrast are kept in the returned Dataframe.\n",
    "    The same filtering is done for the cosine col of the investigated cluster.\n",
    "    \n",
    "    For Filtering: for each col (foldchanges/ cosine) the thresholds to get significant values in that col\n",
    "    are calculated by tfcomb.utils.get_threshold. All rows (tf-pairs), which are not in the threshold \n",
    "    (e.g. >95% percentile for log2foldchange or 99.9% percentile) are removed from the datframe (df). \n",
    "    Threshold are calculated on the original dataframe (df)\n",
    "    Filtering/Reduction of the results is done on a copy of the original dataframe.\n",
    "    \n",
    "    This is done step by step:\n",
    "    e.g. 1. thresholds for column \"log2change_cluster1/cluster2\" are calculated on the original df.\n",
    "         2. all rows (tf-pairs) of the dataframe,\n",
    "            where the values of the investigated column (log2change_cluster1/cluster2) are not in the thresholds,\n",
    "            are removed from the copy of the original dataframe.\n",
    "        These steps are done for each column.\n",
    "\n",
    "    ---\n",
    "    Parameter:\n",
    "    df: pd.DataFrame\n",
    "        DiffCombObj Rules\n",
    "        e.g.:\n",
    "        index   cosine_cluster1 log2change_cluster1/cluster2 log2change_cluster1/cluster3 log2change_cluster1/cluster4\n",
    "        TF1-TF2  0.20                        3.4                              1                        4\n",
    "        TF3-TF4  0.30                       - 0.3                             2                        1\n",
    "        TFX-TFY  0.15                        8                                3                        -4\n",
    "        ...\n",
    "    \n",
    "    cosine_col: string\n",
    "        Name of the cluster, which is investigated and name of the cosine col\n",
    "    \n",
    "    cosine_threshold: float,\n",
    "        Threshold value for the cosine col. All values of the cosine col are investigated\n",
    "        and the threshold value for filtering is calculated. \n",
    "        \n",
    "    log2fc_threshold_percent: float\n",
    "        Threshold value for the log2foldchanges col. All values of the log2foldchanges cols are investigated\n",
    "        and the threshold value for filtering is calculated.\n",
    "    ---\n",
    "    Return pd.Datframe, Filtered df         \n",
    "\n",
    "    '''\n",
    "    # copy of the original dataframe, which will be reduced (remove rows (TF-Pairs),  step by step for each col)\n",
    "    reduced_df = df.copy(deep=True)\n",
    "    for col in df.columns:\n",
    "        # calculate thresholds for log2fc columns or cosine_column\n",
    "        \n",
    "        if col == cosine_col:\n",
    "            # for the cosine column we only want to keep rows with a high value (no negative values),\n",
    "            # so only the upper threshold is important\n",
    "            measure_threshold = utils.get_threshold(df[col], \"both\", percent=cosine_threshold)\n",
    "            upper_threshold = measure_threshold[1]\n",
    "            \n",
    "            # removes tf-pairs (rows), which are smaller than the upper_threshold form the df.\n",
    "            reduced_df = reduced_df[(reduced_df[col] > upper_threshold)]\n",
    "            print(upper_threshold)\n",
    "        else:\n",
    "            # calculates the thresholds for the log2foldchange cols,\n",
    "            # positive and negative is possible, so both thresholds are needed.\n",
    "            measure_threshold = utils.get_threshold(df[col], \"both\", percent=log2fc_threshold_percent)\n",
    "            upper_threshold = measure_threshold[1]\n",
    "            lower_threshold = measure_threshold[0]\n",
    "             # removes tf-pairs (rows), which are smalleror higher than the thresholds form the df.\n",
    "            reduced_df = reduced_df[(reduced_df[col] > upper_threshold) | (reduced_df[col] < lower_threshold)]\n",
    "    # returns only tf-pairs, which are significant        \n",
    "    return reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540bc39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_specific_tf_cos_for_cluster(df:pd.DataFrame, cluster_name:str) -> pd.DataFrame:\n",
    "    '''\n",
    "        Find tf-co-occurences for a cluster/celltype (cluster_name), that are specific for that cluster\n",
    "        in the associated tissue.\n",
    "        \n",
    "        ---\n",
    "        Parameters:\n",
    "            df:pd.DataFrame\n",
    "                 rules of a DiffCombObj. (Differential analysis)\n",
    "\n",
    "            cluster_name: string\n",
    "                name of the cluster/celltype, that is investigated\n",
    "        ---\n",
    "        Return pd.Dataframe with tf-pairs, that show a high difference (log2foldchange) to the other clusters in the the tissue\n",
    "        and are significantly occureing (cosine) in the investigated cluster (cluster_name).   \n",
    "        \n",
    "    '''\n",
    "    # Get only the columns associated with the investigated cluster of the differential analysis,\n",
    "    # that belongs to the tissue of the cluster.\n",
    "    # reduce dataframe(df) to relevant columns assocaiated with the cluster\n",
    "    cluster_cols = list(filter(lambda x: f'{cluster_name}' in x , df.columns))\n",
    "    # print(cluster_cols)\n",
    "    relevant_cluster_cols = []\n",
    "    # Add cosine value for the investigated cluster\n",
    "    cluster_cosine_col_name = f\"{cluster_name}_cosine\"\n",
    "    relevant_cluster_cols.append(cluster_cosine_col_name) \n",
    "    for entry in cluster_cols:\n",
    "        if (f'{cluster_name}/' in entry) or (f'/{cluster_name}_cosine_log2fc' in entry):\n",
    "            relevant_cluster_cols.append(entry)\n",
    "   # print(logfc_cluster_cols)\n",
    "    print(len(relevant_cluster_cols))\n",
    "    \n",
    "    # Get only the values (cosine of cluster + log2fc with each contrast of to the cluster) for the cluster to investigate .\n",
    "    reduced_df = df[relevant_cluster_cols]\n",
    "    print(f'Initial TF-pairs-Count: {reduced_df.shape}')\n",
    "\n",
    "   # Filter out rows with 0.00   \n",
    "    # Count all entries in a row , which do not have a zero(0.00) in it.\n",
    "    # e.g. 15 cols have 0.00 => val_counts = 0, 10 cols not have a 0.00 => val_counts = 10 \n",
    "    val_counts = reduced_df[~reduced_df.isin([0])].count(axis=1).sort_values()\n",
    "    \n",
    "    # Set threshold \n",
    "    selection_threshold = len(relevant_cluster_cols) # e.g. 15, could be varyied\n",
    "    # Keep all entries, which have more/same values that are higher than the threshold\n",
    "    tfs_occ = val_counts[val_counts >= selection_threshold].index\n",
    "    result = reduced_df.loc[tfs_occ]\n",
    "    print(f'Zero filtered TF-pairs-Count: {result.shape}')\n",
    "    \n",
    "    # We would like to find TF-pairs that show a significant change in the log2changes in each contrast, because\n",
    "    # this indicates a TF-Pair, which is striking for the investigated cluster in that tissue.\n",
    "    # And a high cosine would be a indication, that the found tf-pair is really a tf-co-occurence in that cluster.\n",
    "    # Filtering: log2changes and cosine cols to get tf-pairs that have a log2change,\n",
    "    # that shows a high difference to all other clusters in the tissue and a significant cosine value.\n",
    "    significants = get_significant_rules(df=result, cosine_col=cluster_cosine_col_name, cosine_threshold=0.001, log2fc_threshold_percent=0.05)\n",
    "    \n",
    "    print(f'Cluster: {cluster_name}: {significants.shape} ,tf-pairs with significant log2fc-changes in comparison to all the other clusters in tissue')\n",
    "    print(f'Done: Find specific tf co-occurences for cluster{cluster_name}.')\n",
    "    \n",
    "    return significants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce5809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def investigate_differential_analysis_per_tissue(tissues=[]):\n",
    "    '''\n",
    "    Investigate the differential analysis of tf-comb for each tissue.\n",
    "    ---\n",
    "    Parameters:\n",
    "    tissues: []\n",
    "    Tissues that have differential analysis.\n",
    "    ---\n",
    "    Exception:\n",
    "        Catch exception for cluster analysis and continues with analysing the next cluster.\n",
    "    \n",
    "    '''\n",
    "    for tissue in tissues:\n",
    "        print(f\"Start analyse cluster for {tissue}:\")\n",
    "        answer_save_path = f\"{answers_path}{tissue}/\"\n",
    "        # Check if  folder for path already exists for tissue, if not create new one\n",
    "        if not os.path.exists(answer_save_path):\n",
    "             pathlib.Path(answer_save_path).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # folder errors\n",
    "        error_path = f\"{answers_path}{tissue}/errors/\"\n",
    "        # Check if  folder for path already exists for tissue, if not create new one\n",
    "        if not os.path.exists(error_path):\n",
    "             pathlib.Path(error_path).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # load the diffcombobj for the tissue \n",
    "        diff_obj = DiffCombObj().from_pickle(f\"{differential_analysis_path}{tissue}/{tissue}_normalized.pkl\")\n",
    "        # get the rules (tf-pairs) of the diffcombobj.\n",
    "        diff_rules = diff_obj.rules\n",
    "        \n",
    "        # read in the filenames of the original tfcomobj with the executed market basket analysis. \n",
    "        files_main_mb = read_in_file_names_of_folder(rel_path=f\"{main_analysis_path}{tissue}\")\n",
    "        \n",
    "        # Iterate over each cluster.\n",
    "        for i, file in enumerate(files_main_mb):\n",
    "            # print(file)\n",
    "            cluster_name = file.split('.pkl')[0]\n",
    "            print(f\"Start Find specific tf-cos for: {cluster_name}\")\n",
    "            try:\n",
    "                # res contains a pd.dataframe, that contains tf-pairs, \n",
    "                # that have significant log2changes/ and a significant cosine value for the investigated cluster\n",
    "                # compared to the other clusters in the tissue. This TF-pairs could be interesting for further investigation\n",
    "                # ,because they show a significant difference to all the other clusters in the tissue.\n",
    "                res = find_specific_tf_cos_for_cluster(df=diff_rules, cluster_name=cluster_name)\n",
    "\n",
    "                # save res as .pkl\n",
    "                res.to_pickle(f\"{answer_save_path}{cluster_name}.pkl\")\n",
    "            except Exception as err:\n",
    "                print(f\"ERROR: Could not proceed with analysis for cluster: {cluster_name}\")\n",
    "                print(f\"{err}\")\n",
    "                df = pd.DataFrame()\n",
    "                # just save a csv with the clustername as file name,so\n",
    "                # that we later know that an error happened for this cluster.\n",
    "                df.to_csv(f\"{error_path}{cluster_name}.csv\")\n",
    "                print(f\"Continue with next cluster.\")\n",
    "                continue\n",
    "    print(\"Done investigating diff analysis!\")\n",
    "\n",
    "           \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378e96c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "investigate_differential_analysis_per_tissue(tissues=diff_mb_tissues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad67ae86",
   "metadata": {},
   "source": [
    "### Answer for: \n",
    "a) The found TF-pair occures only in a single cluster of a tissue:\n",
    "     e.g. Cluster1 has TF1-TF1 and the other cluster in the tissue do not have TF1-TF1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc4c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rows_with_same_value(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Removes all rows of a Dataframe that do not have the same value in each column and\n",
    "    returns the reduced dataframe.\n",
    "    '''\n",
    "    return df[df.apply(lambda x: min(abs(x)) == max(abs(x)), 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde71dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get folder names of the tissues.\n",
    "answers_mb_tissues = get_folder_names_in_folder(rel_folder_path=answers_path)\n",
    "print(answers_mb_tissues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d4c2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We check now the TF-pairs, that have significant log2changes/ \n",
    "and a significant cosine value for the investigated clusters.\n",
    "If the log2foldchange for each contrast (compared clusters in the tissue) has the same value,\n",
    "the tf-pair is only occureing in the investigated cluster. \n",
    "So The found TF-pair occures only in a single cluster of that tissue. \n",
    "This tf-pair could be interesting for further investigations.\n",
    "'''\n",
    "cluster_with_specials= []\n",
    "for tissue in answers_mb_tissues:\n",
    "    \n",
    "    print(f\"Start analysis {tissue}:\")\n",
    "    answer_specials_save_path = f\"{answers_path}{tissue}/specials/\"\n",
    "    # Check if  folder for path already exists for tissue, if not create new one\n",
    "    if not os.path.exists(answer_specials_save_path):\n",
    "         pathlib.Path(answer_specials_save_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # file names of pd.dataframes with the significant tf-pairs in it.\n",
    "    files = read_in_file_names_of_folder(rel_path=f\"{answers_path}{tissue}\")\n",
    "    for i, file in enumerate(files):\n",
    "        # print(file)\n",
    "        cluster_name = file.split('.pkl')[0]\n",
    "        \n",
    "        # Read in significant tf-pairs\n",
    "        df = pd.read_pickle(f\"{answers_path}{tissue}/{file}\")\n",
    "\n",
    "        # has to remove cosine from dataframe, to get only the log2foldchanges\n",
    "        # for each contrast (compared clusters in the tissue), to check if they have the same value in each column\n",
    "        df_copy = df.copy()\n",
    "        cosine_col_name = df_copy.columns[0]\n",
    "        cosine_col = df_copy[cosine_col_name]\n",
    "        df_only_log2fc = df_copy.drop(columns=[cosine_col_name])\n",
    "        \n",
    "        # find tf-pairs, that have the same value in each log2foldchange column\n",
    "        df_res = find_rows_with_same_value(df_only_log2fc)\n",
    "        \n",
    "        # check if we found a tf-co-occurence which is significant and only occures in one cluster of a tissue\n",
    "        if df_res.shape[0] > 0: \n",
    "            print(f\"Cluster: {cluster_name}, wich has tf-pairs that only occure in this cluster for tissue {tissue}.Found: {str(df_res.shape[0])}\")\n",
    "            #add cosine value back to dataframe\n",
    "            df_res[cosine_col_name]= cosine_col\n",
    "            cluster_with_specials.append(df_res)\n",
    "            # save the tf-pairs as csv, if we found some.\n",
    "            df_res.to_csv(f\"{answer_specials_save_path}{cluster_name}.csv\")\n",
    "        \n",
    "        print(f\"Could not find single occurences in cluster {cluster_name}.\")\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482617be",
   "metadata": {},
   "source": [
    "### Checking - The found TF-pair occures only in a single cluster of a tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c3c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cluster_with_specials)\n",
    "cluster_with_specials[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d1f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = CombObj().from_pickle(f\"{main_analysis_path}/C1PX3_thoracic_aorta/C1PX3_thoracic_aorta.7_peaks.pkl\")\n",
    "comb.rules.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493c4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(comb.rules.loc['TBXT-GLI3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d951a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f\"{answers_path}/C1PX3_thoracic_aorta/C1PX3_thoracic_aorta.7_peaks.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef9d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e034e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copied = df.copy()\n",
    "\n",
    "cosine_col_name = df_copied.columns[0]\n",
    "cosine_col = df_copied[cosine_col_name]\n",
    "dropped = df_copied.drop(columns=[cosine_col_name])\n",
    "dropped\n",
    "#df_copied.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf5d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = find_rows_with_same_value(dropped)\n",
    "df1[cosine_col_name]= cosine_col\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caae383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6bb600",
   "metadata": {},
   "outputs": [],
   "source": [
    "combObj = CombObj().from_pickle(f\"{main_analysis_path}/JF1O6_body_of_pancreas/JF1O6_body_of_pancreas.3_peaks.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edfbfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combObj.rules\n",
    "\n",
    "c = combObj.select_top_rules(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f2cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_threshold = utils.get_threshold(combObj.rules['cosine'], \"both\", percent=0.001)\n",
    "measure_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5cf7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combObj.rules.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927e2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c.rules\n",
    "r = combObj.rules\n",
    "r[(r['cosine'] >= 0.06808819506421941)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e66116",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.loc['OVOL1-OTX1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6642cd7",
   "metadata": {},
   "source": [
    "# OLD\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9597b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyses with whole diffcombj\n",
    "diff_file_names=read_in_file_names_of_folder(rel_path=differential_analysis_path)\n",
    "\n",
    "normalized_diff_objects = []\n",
    "diff_objects = []\n",
    "\n",
    "for file in diff_file_names:\n",
    "    obj = DiffCombObj().from_pickle(f\"{differential_analysis_path}{file}\")\n",
    "    if \"normalized\" in file:\n",
    "        normalized_diff_objects.append(obj)\n",
    "    else:\n",
    "        diff_objects.append(obj)\n",
    "\n",
    "print(normalized_diff_objects)\n",
    "print(diff_objects) \n",
    "\n",
    "normalized_dfs = []\n",
    "for obj in normalized_diff_objects:\n",
    "    normalized_dfs.append(obj.rules)\n",
    "print(\"Done: Preparing rules of DiffObj\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d6ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = normalized_diff_objects[0]\n",
    "t = normalized_diff_objects[0].rules\n",
    "t[t['right-lobe-of-liver.10_cosine'] > 0.7]\n",
    "obj.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3836030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = []\n",
    "for df in normalized_dfs:\n",
    "\n",
    "    for i, file in enumerate(files_main_mb):\n",
    "        # print(file)\n",
    "        cluster_name = file.split('.pkl')[0]\n",
    "        print(cluster_name)\n",
    "        \n",
    "        # reduce to relevant columns of cluster\n",
    "        cluster_cols = list(filter(lambda x: f'{cluster_name}' in x , df.columns))\n",
    "        # NOT WORKING: logfc_cluster_cols = list(filter(lambda x: (f'{cluster_name}/' || f'/{cluster_name}') in x , cluster_cols)) \n",
    "        # This is important: for right-lob-of-liver-1 ,     #right-lobe-of-liver.10_cosine\n",
    "        logfc_cluster_cols = []\n",
    "        for entry in cluster_cols:\n",
    "            if (f'{cluster_name}/' in entry) or (f'/{cluster_name}_cosine_log2fc' in entry):\n",
    "                logfc_cluster_cols.append(entry)\n",
    "        \n",
    "        #print(logfc_cluster_cols)\n",
    "        print(len(logfc_cluster_cols))\n",
    "        #print(logfc_cluster_cols)\n",
    "        \n",
    "        reduced_df = df[logfc_cluster_cols]\n",
    "        print(f'Initial Count: {reduced_df.shape}')\n",
    "        \n",
    "        # Count all entries in a row , which do not have a zero(0.00) in it.\n",
    "        # e.g. 15 cols have 0.00 => val_counts = 0, 10 cols not have a 0.00 => val_counts = 10 \n",
    "        val_counts = reduced_df[~reduced_df.isin([0])].count(axis=1).sort_values()\n",
    "        #print(tmp_val_counts)\n",
    "        # Set threshold \n",
    "        selection_threshold = len(logfc_cluster_cols) # z.B 15 could be varyied\n",
    "        \n",
    "        ## Keep all entries,which do have more values different higher than the threshold\n",
    "        tfs_occ = val_counts[val_counts >= selection_threshold].index\n",
    "        result = reduced_df.loc[tfs_occ]\n",
    "        print(f'Zero filtered: {result.shape}')\n",
    "        \n",
    "        significants = get_significant_log2fc_rules(result, threshold_percent=0.05)\n",
    "        results_df.append(significants)\n",
    "        print(f'Cluster: {cluster_name}: {significants.shape} ,tf-pairs with significant log2fc-changes in comparison to all the other clusters in tissue: {tissue_name} ')\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af3a075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = results_df[0]\n",
    "print(df1.shape)\n",
    "df1\n",
    "# found tf-pairs, which have significant changes in comparison to all the other clusters in the tissue\n",
    "# this 10 tf-pairs of cluster 10, show significant changes in comparion to all the other clusters in the tissue right lob of liver. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fd4e9f",
   "metadata": {},
   "source": [
    "#####  nur cosine werte vergleichbar, daher zum finden von spezifischen tf-cos nur cosines nutzen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b900b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = compare_obj.rules\n",
    "df = pd.DataFrame(td.loc['EN2-MYBL2'])\n",
    "df.head(50)\n",
    "test\n",
    "\n",
    "# nur cosine werte vergleichbar, daher zum finden von spezifischen tf-cos nur cosines nutzen.  \n",
    "np.percentile(test['right-lobe-of-liver.11_cosine'], 75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a033b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['right-lobe-of-liver.11_cosine'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48bb61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster 6\n",
    "df1 = results_df[13]\n",
    "print(df1.shape)\n",
    "df1.head(50)\n",
    "df1.loc['Sox17-Dlx4':'TP63-FOSJUNB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f4388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering if, nan values occure\n",
    "filtered = df[logfc_cluster_cols]\n",
    "\n",
    "val_counts = filtered.count(axis=1).sort_values()\n",
    "#print(val_counts)\n",
    "tfs_occ = val_counts[val_counts >=16].index\n",
    "final = filtered.loc[tfs_occ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b10cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = normalized_dfs[0]\n",
    "cluster_name = \"right-lobe-of-liver.1\"\n",
    "cluster_cols = list(filter(lambda x: f'{cluster_name}' in x , df.columns))\n",
    "# NOT WORKING: logfc_cluster_cols = list(filter(lambda x: (f'{cluster_name}/' || f'/{cluster_name}') in x , cluster_cols)) \n",
    "# This is important: for right-lob-of-liver-1 \n",
    "logfc_cluster_cols = []\n",
    "for entry in cluster_cols:\n",
    "    if (f'{cluster_name}/' in entry) or (f'/{cluster_name}_cosine_log2fc' in entry):\n",
    "        logfc_cluster_cols.append(entry)\n",
    "        \n",
    "tmp = df[logfc_cluster_cols]\n",
    "# wtf, tmp[~tmp.isin([0])]??\n",
    "tmp_val_counts = tmp[~tmp.isin([0])].count(axis=1).sort_values()\n",
    "#print(tmp_val_counts)\n",
    "tmp_tfs_occ = tmp_val_counts[tmp_val_counts == len(logfc_cluster_cols)].index\n",
    "result = tmp.loc[tmp_tfs_occ]\n",
    "print(result.shape)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed56edb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = normalized_dfs[0]\n",
    "cluster_name = \"right-lobe-of-liver.1\"\n",
    "cluster_cols = list(filter(lambda x: f'{cluster_name}' in x , df.columns))\n",
    "# NOT WORKING: logfc_cluster_cols = list(filter(lambda x: (f'{cluster_name}/' || f'/{cluster_name}') in x , cluster_cols)) \n",
    "# This is important: for right-lob-of-liver-1 \n",
    "logfc_cluster_cols = []\n",
    "for entry in cluster_cols:\n",
    "    if (f'{cluster_name}/' in entry) or (f'/{cluster_name}_cosine_log2fc' in entry):\n",
    "        logfc_cluster_cols.append(entry)\n",
    "        \n",
    "tmp = df[logfc_cluster_cols]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89acdd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_threshold_1 = utils.get_threshold(result['right-lobe-of-liver.10/right-lobe-of-liver.1_cosine_log2fc']\n",
    "                                        , \"both\", percent=0.05)\n",
    "measure_threshold_2 = utils.get_threshold(result['right-lobe-of-liver.11/right-lobe-of-liver.1_cosine_log2fc']\n",
    "                                        , \"both\", percent=0.05)\n",
    "print(f'1: {measure_threshold_1}')\n",
    "print(f'1: {measure_threshold_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31975340",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_threshold_1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dda76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t[t['right-lobe-of-liver.10_cosine'] > 0.7]\n",
    "reduced_result_1 = result[(result['right-lobe-of-liver.10/right-lobe-of-liver.1_cosine_log2fc'] > measure_threshold_1[1]) | (result['right-lobe-of-liver.10/right-lobe-of-liver.1_cosine_log2fc'] < measure_threshold_1[0])]\n",
    "reduced_result = reduced_result_1[(reduced_result_1['right-lobe-of-liver.11/right-lobe-of-liver.1_cosine_log2fc'] > measure_threshold_2[1]) | (reduced_result_1['right-lobe-of-liver.11/right-lobe-of-liver.1_cosine_log2fc'] < measure_threshold_2[0])]\n",
    "reduced_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70edc13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9893bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = pd.DataFrame(result.mean(axis=1), columns=['mean'])\n",
    "m1['sum'] = result.sum(axis=1)\n",
    "m1.plot.hist(by='mean', bins=100)\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1782c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = filtered.fillna(0)\n",
    "tmp_val_counts = tmp[~tmp.isin([0])].count(axis=1).sort_values()\n",
    "\n",
    "print(tmp_val_counts)\n",
    "tmp_tfs_occ = tmp_val_counts[tmp_val_counts >=16].index\n",
    "result = filtered.loc[tmp_tfs_occ]\n",
    "\n",
    "m1 = pd.DataFrame(result.mean(axis=1), columns=['mean'])\n",
    "m1['sum'] = result.sum(axis=1)\n",
    "m1.plot.hist(by='mean', bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6b31b0",
   "metadata": {},
   "source": [
    "## Old: Self implemented - Differential analysis - comparing each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9bb030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mb market basket analysis\n",
    "files_main_mb= read_in_file_names_of_folder(rel_path=main_analysis_path)\n",
    "print(f\"Count of Files: {len(files_main_mb)}\")\n",
    "print(f\"Files: {files_main_mb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172636a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diff analysis for all clusters of a tissue:\n",
    "# TODO: what should be compared ? All of a Tissue? or All? Naming?\n",
    "tissue_name = 'right-lobe-of-liver'\n",
    "combObj_to_compare = []\n",
    "for i, file in enumerate(files_main_mb):\n",
    "    print(file)\n",
    "    name_i = file.split('.pkl')[0]\n",
    "    tissue_name = file.split('.')[0]\n",
    "    obj = CombObj().from_pickle(f\"{main_analysis_path}{file}\")\n",
    "    obj.set_prefix(name_i)\n",
    "    #print(obj)\n",
    "    combObj_to_compare.append(obj)\n",
    "    \n",
    "compare_obj = DiffCombObj(combObj_to_compare, measure=\"cosine\", join=\"outer\", fillna=True)\n",
    "compare_obj.to_pickle(f'{differential_analysis_path}{tissue_name}.pkl')\n",
    "compare_obj.normalize()\n",
    "compare_obj.calculate_foldchanges()\n",
    "compare_obj.simplify_rules()\n",
    "compare_obj.to_pickle(f'{differential_analysis_path}{tissue_name}_normalized.pkl')\n",
    "#selection does not work?\n",
    "#selected_std = compare_obj.select_rules()\n",
    "#selected_std.to_pickle(f'{differential_analysis_selection_path}{tissue_name}.pkl')\n",
    "print(\"Done differential analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = compare_obj.rules\n",
    "\n",
    "tmp_val_counts = td[td.isin([0])].count(axis=1).sort_values()\n",
    "#tmp_val_counts = td[td.isna()].count(axis=1).sort_values()\n",
    "\n",
    "print(tmp_val_counts)\n",
    "#tmp_tfs_occ = tmp_val_counts[tmp_val_counts >=16].index\n",
    "#result = filtered.loc[tmp_tfs_occ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5266b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check original market basket analysis for count of tf-cooccurences\n",
    "print(compare_obj.rules.shape)\n",
    "count_of_all = 0\n",
    "count_of_all_significant = 0\n",
    "for obj in combObj_to_compare:\n",
    "    print(obj.prefix)\n",
    "    print(obj.rules.shape)\n",
    "    obj.simplify_rules()\n",
    "    print(obj.rules.shape)\n",
    "    count_of_all = count_of_all + obj.rules.shape[0]\n",
    "    sig = obj.select_significant_rules()\n",
    "    print(sig.rules.shape)\n",
    "    count_of_all_significant = count_of_all_significant + sig.rules.shape[0]\n",
    "\n",
    "print(\"all simplyfied for tissue\")\n",
    "print(count_of_all)    \n",
    "print(\"all simplyfied for tissue and significant\")\n",
    "print(count_of_all_significant) \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f3d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diff analysis between each cluster:\n",
    "for i, file in enumerate(files_main_mb):\n",
    "    print(file)\n",
    "    name_i = file.split('.pkl')[0]\n",
    "    \n",
    "    for j in range(i + 1, len(files_main_mb), 1):\n",
    "        file_j = files_main_mb[j]\n",
    "        name_j = file_j.split('.pkl')[0]\n",
    "        print(j)\n",
    "        print(name_j)\n",
    "        A = CombObj().from_pickle(f\"{main_analysis_path}{file}\")\n",
    "        print(A)\n",
    "        A.set_prefix(name_i)\n",
    "        B = CombObj().from_pickle(f\"{main_analysis_path}{file_j}\")\n",
    "        print(B)\n",
    "        B.set_prefix(name_j)\n",
    "        compare_obj = A.compare(B)\n",
    "        compare_obj.to_pickle(f'{differential_analysis_path}{name_i}__{name_j}.pkl')\n",
    "        \n",
    "        selected_std = compare_obj.select_rules()\n",
    "        \n",
    "        #TODO: Save autamatically generated thresholds\n",
    "        # utils.get_threshold(new.rules.iloc[:,4], 'both', percent=0.05)\n",
    "        # logfc threshold (-xxx , +xxx)\n",
    "        #  utils.get_threshold(new.rules.iloc[:,2:4].mean(axis=1), 'upper', percent=0.05)\n",
    "        # cosine threshold\n",
    "        selected_std.to_pickle(f'{differential_analysis_selection_path}{name_i}__{name_j}.pkl')\n",
    "        \n",
    "        break;\n",
    "        \n",
    "        \n",
    "print(\"Done differential analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b6701",
   "metadata": {},
   "source": [
    "## OLD implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f3afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_diff_obj_dataframe(diff_obj: DiffCombObj) -> pd.DataFrame:\n",
    "    \n",
    "    # possible prefix names ['right-lobe-of-liver.10', 'right-lobe-of-liver.16']\n",
    "    df = diff_obj.rules\n",
    "    tissue_name_c1 , cluster_nr_c1  = diff_obj.prefixes[0].split('.')\n",
    "    tissue_name_c2 , cluster_nr_c2  = diff_obj.prefixes[1].split('.')\n",
    "    suff = \"\"\n",
    "    if tissue_name_c1 == tissue_name_c2:\n",
    "        suff += f\"_{tissue_name_c1}\"\n",
    "    else:\n",
    "        suff += f\"_{tissue_name_c1}_{tissue_name_c2}\"\n",
    "\n",
    "    if cluster_nr_c1 == cluster_nr_c2:\n",
    "        suff += f\"_{cluster_nr_c1}\"\n",
    "    else:\n",
    "        suff += f\"_{cluster_nr_c1}_{cluster_nr_c2}\"\n",
    "\n",
    "    df['log2fc_class'] = df.apply(lambda x: 'negativ' if x[4] < 0 else 'positiv', axis=1)\n",
    "    df.columns = [f'{x}{suff}' for x in df.columns]\n",
    "    \n",
    "    return df.copy(deep=True)\n",
    "\n",
    "\n",
    "# Find the specific tf_cooccurences of a tissue that unique for the specific cluster in the tissue.\n",
    "# 1. Diff analyse , \n",
    "# 2. Read in Diffanalyse for the specific cluster\n",
    "# 3. Find tf-cooccurence of the diffob , which are occuring in each cluster\n",
    "# Read in file Names of all analysis\n",
    "files_main_mb= read_in_file_names_of_folder(rel_path=main_analysis_path)\n",
    "print(f\"Count of Files: {len(files_main_mb)}\")\n",
    "#print(f\"Files: {files_main_mb}\")\n",
    "\n",
    "files_diff= read_in_file_names_of_folder(rel_path=differential_analysis_path)\n",
    "print(f\"Count of Files: {len(files_diff)}\")\n",
    "\n",
    "test = \"\"\n",
    "for file_mb in files_main_mb:\n",
    "    cluster_name = file_mb.split('.pkl')[0]\n",
    "    print(cluster_name)\n",
    "    diffs = list(filter(lambda x: cluster_name in x, files_diff))\n",
    "    print(len(diffs))\n",
    "    print(diffs)\n",
    "    \n",
    "    # Keeps the read in DiffCombObj diff_objects:\n",
    "    diff_objects = []\n",
    "    \n",
    "    for diff in diffs:\n",
    "        diff_obj = DiffCombObj().from_pickle(f\"{differential_analysis_selection_path}{diff}\")\n",
    "        diff_objects.append(diff_obj)\n",
    "    \n",
    "    erg = None\n",
    "    for i in range(len(diff_objects)-1):\n",
    "        \n",
    "        if erg is None:\n",
    "            obj_1= diff_objects[i]\n",
    "            obj_2 = diff_objects[i + 1]\n",
    "            df1 = prepare_diff_obj_dataframe(diff_obj = obj_1)\n",
    "            df2 = prepare_diff_obj_dataframe(diff_obj = obj_2)\n",
    "            \n",
    "            erg = df1.merge(df2, how='outer', left_index=True, right_index=True)\n",
    "        else:\n",
    "            obj_2 = diff_objects[i + 1] \n",
    "            df2 = prepare_diff_obj_dataframe(diff_obj = obj_2)\n",
    "            erg = erg.merge(df2, how='outer', left_index=True, right_index=True)\n",
    "       \n",
    "    test = erg\n",
    "    erg.to_pickle(path=f\"{answers_path}{cluster_name}.pkl\")\n",
    "    \n",
    "print(\"Done\")    \n",
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde5900",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_file_names=read_in_file_names_of_folder(rel_path=answers_path)\n",
    "print(answer_file_names)\n",
    "cluster_dfs = []\n",
    "df = None\n",
    "for name in answer_file_names:\n",
    "    df = pd.read_pickle(f\"{answers_path}{name}\")\n",
    "    cluster_dfs.append(name)\n",
    "    df = df\n",
    "\n",
    "    #df.groupby(['class', 'value']).count()\n",
    "    break;\n",
    "filter_columns = list(filter(lambda x: 'log2fc_class' in x , df.columns))\n",
    "#len(filter_columns)\n",
    "filtered_df = df[df[filter_columns].notna().all(1)] #\n",
    "filtered_df\n",
    "df\n",
    "#df3.iloc[:, 2:3]\n",
    "#df = pd.read_pickle(f\"{answers_path}right-lobe-of-liver.6.pkl\")\n",
    "#df = pd.read_pickle(f\"{differential_analysis_selection_path}{right-lobe-of-liver.6.pkl}\")\n",
    "\n",
    "\n",
    "#original = CombObj().from_pickle(f\"{main_analysis_path}right-lobe-of-liver.6.pkl\")\n",
    "#original.rules.loc[df.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee683c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f\"{answers_path}right-lobe-of-liver.6.pkl\")\n",
    "selection = DiffCombObj().from_pickle(f\"{differential_analysis_selection_path}right-lobe-of-liver.10__right-lobe-of-liver.16.pkl\")\n",
    "selection_orig = DiffCombObj().from_pickle(f\"{differential_analysis_path}right-lobe-of-liver.10__right-lobe-of-liver.16.pkl\")\n",
    "selection_orig\n",
    "selection\n",
    "\n",
    "original = CombObj().from_pickle(f\"{main_analysis_path}right-lobe-of-liver.6.pkl\")\n",
    "original.rules.loc[df.index]\n",
    "selection.prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245c7d57",
   "metadata": {},
   "source": [
    "### Try and Error section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c1e564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mb_obj = CombObj().from_pickle(f\"{main_analysis_path}right-lobe-of-liver.10.pkl\")\n",
    "obj_1 = DiffCombObj().from_pickle(f\"{differential_analysis_path}right-lobe-of-liver.16__right-lobe-of-liver.1.pkl\")\n",
    "obj_2 = DiffCombObj().from_pickle(f\"{differential_analysis_path}right-lobe-of-liver.16__right-lobe-of-liver.2.pkl\")\n",
    "obj_3 = DiffCombObj().from_pickle(f\"{differential_analysis_path}right-lobe-of-liver.16__right-lobe-of-liver.3.pkl\")\n",
    "obj_4 = DiffCombObj().from_pickle(f\"{differential_analysis_path}right-lobe-of-liver.16__right-lobe-of-liver.4.pkl\")\n",
    "obj_5 = DiffCombObj().from_pickle(f\"{differential_analysis_path}right-lobe-of-liver.16__right-lobe-of-liver.5.pkl\")\n",
    "obj_6 = DiffCombObj().from_pickle(f\"{differential_analysis_path}right-lobe-of-liver.16__right-lobe-of-liver.6.pkl\")\n",
    "#mb_obj.rules\n",
    "#type(diff_obj.rules)\n",
    "#diff_obj2.rules\n",
    "df_diff = pd.concat([obj_1.rules, obj_2.rules, obj_3.rules, obj_4.rules, obj_5.rules, obj_6.rules], join=\"inner\")\n",
    "\n",
    "\n",
    "\n",
    "#df_diff2 = pd.concat([diff_obj_1_1.rules,diff_obj2.rules, diff_obj1_2.rules])\n",
    "\n",
    "unified_duplicates = df_diff[df_diff.duplicated(subset=['TF1', 'TF2'], keep='first')]\n",
    "\n",
    "df_diff2 = pd.concat([unified_duplicates, diff_obj1_2.rules])\n",
    "\n",
    "unified_duplicates2 = df_diff2[df_diff2.duplicated(subset=['TF1', 'TF2'], keep='first')]\n",
    "\n",
    "#df_diff = df_diff.drop_duplicates(subset=['TF1', 'TF2'])\n",
    "#unified_duplicates\n",
    "#unified_duplicates\n",
    "#unified_duplicates2\n",
    "#diff_obj_1_1.rules\n",
    "#unified_duplicates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3318406",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_1 = DiffCombObj().from_pickle(f\"{differential_analysis_selection_path}right-lobe-of-liver.16__right-lobe-of-liver.1.pkl\")\n",
    "obj_2 = DiffCombObj().from_pickle(f\"{differential_analysis_selection_path}right-lobe-of-liver.16__right-lobe-of-liver.2.pkl\")\n",
    "\n",
    "obj_1.simplify_rules()\n",
    "obj_2.simplify_rules()\n",
    "obj3 = obj_1.rules.merge(obj_2.rules, left_index=True, right_index=True, suffixes=(f\"_{obj_1.prefixes[0]}_{obj_1.prefixes[1]}\", f\"_{obj_2.prefixes[0]}_{obj_2.prefixes[1]}\"))\n",
    "obj3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85338848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['log2fc_class'] = df.apply(lambda x: 'negativ' if x[4] < 0 else 'positiv', axis=1)\n",
    "\n",
    "#removedNAN = df[df.notna().all(1)]\n",
    "\n",
    "#df2 = removedNAN[(removedNAN[filter_columns] > 0.0) | (removedNAN[filter_columns] < 0.0)]\n",
    "#df2[df2.notna().all(1)]\n",
    "#filtered_df = df[df[filter_columns].notna().all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d35c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_obj_1_1.rules.loc['Foxd3-ONECUT2']\n",
    "diff_obj2.rules.loc['Foxd3-ONECUT2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732674cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "top30C = selectedC.select_top_rules(n=30)\n",
    "top30C.rules.head(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd725aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "                    'value1': [-1, -3.33, 3, 6,8,7],\n",
    "                    'value2': [-1, 3.33, 3.4, 9,2,7],\n",
    "                    'value3': [1, -3.33, 3, 2,4,7],\n",
    "                    'value4': [1, 3.33, 3, 1,9,7]},\n",
    "                   index=['my1', 'my2', 'my3', 'my4', 'my5', 'my6'])\n",
    "df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo','test'],\n",
    "                    'value': [5, 6, 7, 8, 9]},\n",
    "                  index=['my1', 'not2', 'my3', 'not4', 'my5'])\n",
    "df3 = pd.DataFrame({'rkey': ['new', 'lol'],\n",
    "                    'value': [5, 6]},\n",
    "                  index=['my1', 'not2'])\n",
    "df1\n",
    "\n",
    "#df1.merge(df2, left_on='lkey', right_on='rkey')\n",
    "#erg = df1.merge(df2, left_index=True, right_index=True, suffixes=(\"_test\", \"_test2\"))\n",
    "#erg = df1.merge(df2, how='outer', left_index=True, right_index=True, suffixes=(\"_x\", \"_y\"))\n",
    "#erg = erg.merge(df3, how='outer', left_index=True, right_index=True, suffixes=(\"_x\", \"_\"))\n",
    "#erg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c3de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[(df1['value1'] == 1) & df1['value2']== 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607bc563",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1.apply(lambda x: min(abs(x)) == max(abs(x)), 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c4db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns = [f'{x}_df2' for x in df2.columns]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8024c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x+ 1 for x in df2.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d5305",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['class'] = df1.apply(lambda x: 'niedrig' if x[1] < 5 else 'hoch', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1c3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1['class'] == 'hoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2c8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.groupby(['class', 'value']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa0f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd1175",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.iloc[:, 2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91b30ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "top30C.plot_bubble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa096c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top30C.plot_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedC.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1edc217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cfa1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### OLD \n",
    "# Find the specific tf_cooccurences of a tissue that unique for the specific cluster in the tissue.\n",
    "# 1. Diff analyse , \n",
    "# 2. Read in Diffanalyse for the specific cluster\n",
    "# 3. Find tf-cooccurence of the diffob , which are occuring in each cluster\n",
    "# Read in file Names of all analysis\n",
    "files_main_mb= read_in_file_names_of_folder(rel_path=main_analysis_path)\n",
    "print(f\"Count of Files: {len(files_main_mb)}\")\n",
    "#print(f\"Files: {files_main_mb}\")\n",
    "\n",
    "files_diff= read_in_file_names_of_folder(rel_path=differential_analysis_path)\n",
    "print(f\"Count of Files: {len(files_diff)}\")\n",
    "#print(f\"Files: {files_diff}\")\n",
    "test = \"\"\n",
    "for file_mb in files_main_mb:\n",
    "    cluster_name = file_mb.split('.pkl')[0]\n",
    "    print(cluster_name)\n",
    "    diffs = list(filter(lambda x: cluster_name in x, files_diff))\n",
    "    print(len(diffs))\n",
    "    print(diffs)\n",
    "    \n",
    "    # Keeps the read in DiffCombObj diff_objects:\n",
    "    diff_objects = []\n",
    "    \n",
    "    for diff in diffs:\n",
    "        diff_obj = DiffCombObj().from_pickle(f\"{differential_analysis_selection_path}{diff}\")\n",
    "        diff_objects.append(diff_obj)\n",
    "    \n",
    "    # erste DiffObj dataframe \n",
    "    initial_df = diff_objects[0].rules\n",
    "    \n",
    "    #has neg and pos foldchange\n",
    "    cross_product_merged = initial_df\n",
    "    \n",
    "    # only pos foldchange\n",
    "    pos_merged = initial_df[initial_df.iloc[:,4] > 0.00]\n",
    "    \n",
    "    # only neg foldchange\n",
    "    neg_merged = initial_df[initial_df.iloc[:,4] < 0.00]\n",
    "    for i in range(len(diff_objects)-1):\n",
    "        obj_1= diff_objects[i]\n",
    "        obj_2 = diff_objects[i + 1]\n",
    "            \n",
    "        # cross_product merge rules-dataframe by index (TF´s)\n",
    "        cross_product = cross_product_merged.merge(obj_2.rules, left_index=True, right_index=True, suffixes=(f\"_{obj_1.prefixes[0]}_{obj_1.prefixes[1]}\", f\"_{obj_2.prefixes[0]}_{obj_2.prefixes[1]}\"))\n",
    "        cross_product_merged = cross_product.copy(deep=True)\n",
    "        \n",
    "        # pos merge rules-dataframe by index (TF´s)\n",
    "        obj2_df_pos = obj_2.rules[obj_2.rules.iloc[:,4] > 0.00]\n",
    "        df_pos_merged = pos_merged.merge(obj2_df_pos, left_index=True, right_index=True, suffixes=(f\"_{obj_1.prefixes[0]}_{obj_1.prefixes[1]}\", f\"_{obj_2.prefixes[0]}_{obj_2.prefixes[1]}\"))\n",
    "        pos_merged = df_pos_merged.copy(deep=True)\n",
    "        \n",
    "        # neg merge rules-dataframe by index (TF´s)\n",
    "        obj2_df_neg = obj_2.rules[obj_2.rules.iloc[:,4] < 0.00]\n",
    "        df_neg_merged = neg_merged.merge(obj2_df_neg, left_index=True, right_index=True, suffixes=(f\"_{obj_1.prefixes[0]}_{obj_1.prefixes[1]}\", f\"_{obj_2.prefixes[0]}_{obj_2.prefixes[1]}\"))\n",
    "        neg_merged = df_neg_merged.copy(deep=True)\n",
    "        \n",
    "        \n",
    "    cross_product_merged.to_pickle(path=f\"{answers_path}{cluster_name}_cross.pkl\")\n",
    "    pos_merged.to_pickle(path=f\"{answers_path}{cluster_name}_pos.pkl\")\n",
    "    neg_merged.to_pickle(path=f\"{answers_path}{cluster_name}_neg.pkl\")\n",
    "    \n",
    "print(\"Done\")    \n",
    "test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfcomb_env",
   "language": "python",
   "name": "tfcomb_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
